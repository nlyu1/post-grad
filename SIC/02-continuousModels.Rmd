# Continuous models

## Preliminaries {-}

:::{.definition name="stochastic process"}
Given a probability space $(\Omega, \mca F, \mbb P)$, where 

- $\Omega$ is the sample space. 
- $\mca F$ is a $\sigma$-algebra of events to which probabilities can be assigned. 
- $\mbb P$ is a probability measure on $\mca F$. 
- A random variable is a measurable function $X: \Omega \to \mbb R$. The $\sigma$-algebra generated by $X$ is $\sigma(X) = \{X^{-1}(B) \mid B\in \mbb B(\mbb R)\}\subseteq\mca F$; it encodes the information about $\Omega$ that's revealable by $X$; definition extends naturally to vector-valued random variables (or collection of random variables). 
- $X_1, \dots, X_n$ are **independent** if $\sigma(X_1), \dots, \sigma(X_n)$ are independent: 
\[ 
    P(\{X_j\in A_j\}) = \prod_{j=1}^n P(X_j\in A_j)
\] 
Independence of random variables are defined analogously. 

Let $T\subseteq \mbb R_+$ be the time index; a real-valued **stochastic process** is a measurable map 
\[ 
    X: \Omega \times T \to \mbb R. 
\] 
so that $X_{\forall t\in T}$ is a random variable. A **filtration** $(\mca F_{t\in T})$ is an increasing family of $\sigma$-algebras satisfying $\mca F_0\subseteq \mca F_{0\leq s\leq t}\subseteq \mca F_t\subseteq \mca F$. 
:::

:::{.definition name="filtration and processes"}
The **natural filtration** of a stochastic process $X$ is the filtration $(\mca F_t)$ defined by 
\[ 
    \mca F_t = \sigma(X_s \mid s\leq t). 
\] 
A stochastic process is **adapted** to a filtration $(\mca F_t)$ if $X_t$ is $\mca F_t$-measurable for all $t\in T$; this asks that *the value of $X_t$ is uniquely determined by distinguishable sample partitions known up to time $t$.*
:::

## Brownian process {-}

By intuition, a continuous process should be continuous, variable across time, and real-valued. 

:::{.example name="tentative random walk"}
Given a positive integer $n$, define the binomial process $W_n(t)$ with 

- $W_n(0) = 0$. 
- Layer spacing $\delta = 1/n$. 
- Up and down jumps with equal size $1/\sqrt n$. 
- Measure $\mbb P$ uniform between up and down jumps. 
:::

In other words, given a sequence of i.i.d. $X_j$ with $\pm 1$, define 
\[ 
    W_n\left(\df j n\right) = W_n\left(\df{j-1} n\right) + \df{1}{\sqrt n} X_j
\] 

The definition of $W_n(1)$ is (second argument denoting standard deviation): 
\[ 
    W_n(t) = \df{\sum_{j=1}^{nt} X_j}{\sqrt n}\sim \mca N\left(
        0, \sqrt t
    \right)
\] 

1. Future movements away from a position are independent of the history up to that point. 
2. $W_n(s+t)-W_n(s)\sim \mca N(0, \sqrt t)$. 

:::{.definition #brownian name="Brownian process"}
A process $(W_{t\geq 0})$ is a $\mbb P$-Brownian process iff 

1. $W_t$ is continuous with $W_0=0$. 
2. Under $\mbb P$, the random variable $W_t\sim \mca N(0, t)$. 
3. The increment $W_{s+t} - W_s\sim \mca N(0, t)$ under $\mca P$ and is independent of $\mca F_s$. 

An **exponential Brownian process** is defined by $X_t = \exp(\sigma W_t + \mu t)$. 
:::

:::{.definition name="standard Brownian process"}
The **standard Brownian process** (also known as the **Wiener process**) consists of the following components:

- <u>Sample space $\Omega$ </u>: $C_0([0, \infty)\to \R)$
- $\sigma$-algebra generated by the uniform topology; makes "evaluate the path at finitely many points" measurable. 
- Probability measure $\mbb P:\Omega\to [0, 1]$ given by the Wiener measure (see \@ref(def:wienerMeasure)). 
- <u> Process </u>: $W_t(\omega) = \omega(t)$ for all $t\geq 0$. It is simply the coordinate map; the standard Brownian process $W_t$ is canonical due to the canonical coordinate-map process. 
:::

:::{.remark}
<span style="color:blue">
A Brownian process is a **process-measure pair**! Alternative Brownian processs might exist (see [CMG theorem](#CMG))! A standard Brownian process with previsible drift $W_t+\mu_t$ is not Brownian under the Wiener measure, but is Brownian under a tilted measure. 
</span>
:::

## Stochastic calculus {-}

Recall the classical, Newtonian differential notations: 

1. If $f_t$ and $\tilde f_t$ are differentiable, agreeing at $0$, and $df_t = d\tilde f_t$ (here $df_t$ overloads for the derivative function), then $f_t = \tilde f_t$. 
2. Given differentiable $f$, there is a unique drift $\mu_t$ such that $f_t = f_0 + \int_0^t \mu_s\, ds$ for all $t$. 

:::{.remark}
The differential notation $df = \mu(f, t)\, dt$ is a recipe for building differentiable functions from a drift function. 
:::

Intuition: differentiable functions zoom to tangent lines, while Brownian process zooms to Brownian process; this inspires the following definition:

:::{.definition name="continuous Itô processes, diffusion"}
A **stochastic process** (more restrictive definition) $X_t$ is a continuous process such that 
\begin{align} 
    dX_t &= \sigma_t\, dW_t + \mu_t\, dt \\ 
    X_t &= X_0 + \int_0^t \sigma_s\, dW_s + \int_0^t \mu_s\, ds 
\end{align}
where $\sigma, \mu$ are $\mca F$-previsible processes such that $\int_0^t (\sigma_s^2 + |\mu_s|)\, ds < \infty$ a.s. When $\sigma, \mu$ are only dependent on $X_t$ (instead of the full history), every strong solution is a diffusion. 
:::

:::{.remark name="justification for Brownian process as fundamental building block"}
Brownian process is the continuous limit of equi-probable binary branching processes. Any "reasonable" branching can be approximated by an affine transformation of such branching, with offset and scale given by $\mu_t$ and $\sigma_t$, respectively. 
<span style="color:green"> Any continuous model requiring time-homogeneous, independent shocks and appropriate scale limit dictates Brownian process as the stochastic building block. </span>
:::

Consider $d f(W_t)$ for $f(x)=x^2$. Newtonian intuition suggests $d(W_t^2) = 2W_t\, dW_t$, but this should be checked by 
\[ 
    \text{whether } W_t^2 = \int_0^t d(W_s^2) =^? 2\int_0^t W_s\, dW_s
\] 
Define the RHS integral by approximation; note that the square bracket term has mean $0$ and is independent of $W_{jt/n}$. 
\[ 
    2\int_0^t W_s\, dW_s \approx 2\sum_{j=0}^{n-1} W\left(\df{jt}{n}\right)\left[W\left(\df{(j+1)t}{n}\right) - W\left(\df{jt}{n}\right)\right]_{=0} = 0 
\] 
But $W_t^2$ does not have zero mean, so something is wrong here. Consider the Taylor expansion 
\[ 
    df(W_t) = f'(W_t)\, dW_t + \df 1 2 f''(W_t)\, (dW_t)^2 + \dots 
\] 
In Newtonian differentials, $(dW_t)^2 = 0$, so are higher-order terms. However, 
recall that $W_t - W_s\sim \mca N(0, t-s) = \sqrt{t-s}Z$ and are independent for disjoint partitions: 
\begin{align}
    \int_0^t (dW_t)^2 &\approx \sum_{j=1}^n \left(
        W_{tj/n} - W_{t(j-1)/n}
    \right)^2 \\ 
    &= \sum_{j=1}^n \left(Z_j \sqrt{t/n}\right)^2 = t \sum_{j=1}^n \df{Z_j^2}{n}, \quad Z_j\sim \mca N(0, 1) \text{ i.i.d.} \\ 
    &= t \text{ by law of large numbers} \\ 
    (dW_t)^2 &= dt
\end{align}
Recall that $\Exp[Z^2] = \mrm{Var}(Z) + \Exp[Z]^2 = 1$. The higher orders $(dW_t)^{k\geq 3}$ are negligible. Intuitively, Brownian increments are of order $\sqrt{dt}$. 

:::{.definition name="Itô's formula"}
Given $dX_t = \sigma_t\, dW_t + \mu_t\, dt$ and $f$ deterministic twice continuously differentiable: 
\[ 
    df(X_t) = \left[
        \sigma_t f'(X_t) 
    \right]\, dW_t + \left[
        \mu_t f'(X_t) + \df 1 2 \sigma_t^2 f''(X_t)
    \right]\, dt 
\] 
:::
For example, substituting $f(x)=x^2$ yields 
\[ 
    d(W_t^2) = 2W_t\, dW_t + dt 
\] 
<span style="color:blue">
Note that while $dX_t = \sigma\, dW_t + \mu\, dt \implies X_t = X_0 + \sigma W_t + \mu t$, we have the more general 
\[ 
    dX_t = \sigma_t\, dW_t + \mu_t\, dt \implies X_t = X_0 + \int_0^t \sigma_s\, dW_s + \int_0^t \mu_s\, ds
\] 
The stochastic integral $\int_0^t \sigma_s\, dW_s \neq \left(\int_0^t \sigma_s\, ds \right)W_t$ <u>in general</u>. 
</span>

:::{.example name="common differentials"}
Consider the quadratic and the exponential:

1. Let $dX_t = \sigma_t\, dW_t + \mu_t\, dt$, then 
\[ 
    d(X_t^2) 
    = \left(2\sigma_t X_t\right) \, dW_t + \left(
        2 \mu_t X_t  + \sigma_t^2
    \right)\, dt 
\] 
2. $d e^{W_t} = e^{W_t}\, dW_t + \df 1 2 e^{W_t}\, dt$. 
:::

:::{.example name="exponential diffusion equation with constant volatility"}
\[ 
    dY_t = Y_t\left(\sigma_t \, dW_t + \mu_t\, dt\right)
    \implies 
    Y_t = Y_0 \exp \left[
        \int_0^t \sigma_s\, dW_s + \int_0^t \left(
            \mu_s - \df 1 2 \sigma_s^2 
        \right)\, ds 
    \right]
\] 
:::
<details>
Let $Y_t = f(X_t)$ with $dX_t = \sigma_t\, dW_t + \mu_t\, dt$, matching yields equations 
\[ 
    \hat \sigma_t f'(X_t) = \sigma_t f(X_t), \quad \hat \mu_t f'(X_t) + \df 1 2 \hat \sigma_t^2 f''(X_t) = f(X_t) \mu_t
\] 
Solve for $\hat \sigma_t, f(X_t)$, and $\hat \mu_t$: 
\[ 
    \hat \sigma_t = \sigma_t, \quad f(X_t) = e^{C X_t}, \quad \hat \mu_t + \df 1 2 \hat \sigma_t^2 = \mu_t \implies \hat \mu_t = \mu_t - \df 1 2 \sigma_t^2 
\] 
This gives $dY_t = d f(X_t)$, where the RHS is no longer dependent upon $Y_t$. 
\begin{align}
    Y_t 
    &= \int_0^t dY_s = \int_0^t Y_s\left(\sigma_s \, dW_s + \mu_s\, ds\right) \\ 
    &= \int_0^t d f(X_s) 
    = f(X_t) \\ 
    &= C\exp \left[
        \int_0^t \sigma_s\, dW_s + \int_0^t \left(
            \mu_s - \df 1 2 \sigma_s^2 
        \right)\, ds 
    \right], \quad C=Y_0 
\end{align}
</details>

:::{.proposition name="product rule"}
When $X_t, Y_t$ are adapted to the **same** Brownian process 
\[ 
    dX_t = \sigma_t\, dW_t + \mu_t\, dt, \quad 
    dY_t = \rho_t\, dW_t + \nu_t\, dt 
\] 
We have $d(X_tY_t) = X_t\, dY_t + Y_t\, dX_t + (dX_t)(dY_t)$. 
:::

<details>
\begin{align}
    d(2 X_t Y_t) 
    &= d(X_t + Y_t)^2 - d(X_t^2) - d(Y_t^2) \\ 
    &= \left[
        2(\sigma_t + \rho_t) (X_t + Y_t) \, dW_t + \left(
        2 (\mu_t + \nu_t) (X_t + Y_t)  + (\sigma_t + \rho_t)^2
    \right)\, dt 
    \right] \\ 
    &\quad - \left[
        2\sigma_t X_t \, dW_t + \left(
        2 \mu_t X_t  + \sigma_t^2
    \right)\, dt 
    \right] \\ 
    &\quad - \left[
        2\rho_t Y_t \, dW_t + \left(
        2 \nu_t Y_t  + \rho_t^2
    \right)\, dt 
    \right] \\ 
    &= 2 \left(
        \sigma_t Y_t + \rho_t X_t
    \right)\, dW_t + \left(
        2\mu_t Y_t + 2\nu_t X_t + 2 \sigma_t \rho_t
    \right)\, dt  \\ 
    X_t\, dY_t + Y_t\, dX_t 
    &= X_t \left(
    \rho_t\, dW_t + \nu_t\, dt 
    \right) + Y_t \left(
        \sigma_t\, dW_t + \mu_t\, dt
    \right) \\ 
    &= d(X_tY_t) - \sigma_t \rho_t\, dt 
\end{align}
This yields the product rule by noting that 
$(dX_t)(dY_t) = \sigma_t \rho_t\, dt$ ($dW_t^2 = dt$ and $dt^2 = dt\, dW_t = 0$). 
</details>

<span style="color:blue">
Also note that we cannot apply Ito directly to $X_t\mapsto X_tY_t$ because this is not a deterministic function. 
</span>

## Change of process measure {-}

Define by $\zeta_t$ the Radon-Nikodym derivative taken up to the horizon $t$: i.e. it is the likelihood-ratio map measurable by $\mca F_t$. Fixing a horizon $T$ and calculate the Radon-Nikodym derivative $d\mbb Q/d\mbb P$ at time $T$, we have 
\[ 
    \zeta_t = \mbb E_{\mbb P} \left[
    \df{d\mbb Q}{d\mbb P} \bigg| \mca F_t 
    \right], \quad \forall t\leq T
\] 

:::{.remark}
The expectation above w.r.t. $\mca F_t$ makes sure that $\zeta_t$ is adapted to the information available up to time $t$ only. 

1. In the discrete picture, this expectation equivalently puts a unique value on each node at time $t$. 
2. The expectation is taken w.r.t. $\mbb P$ because $\mbb Q$ is in the numerator (so conditionals sum to $1$), while conditionals in $\mbb P$ are in the denominator. See example below. 
:::

:::{.example name="simple illustration"}
Consider two 2-level binary-tree processes $\mbb Q, \mbb P$ with the first level parameterized by $q_1$, the second by $q_2, q_3$ respectively; same for $p$. 

- Under $\mbb Q$, the tail probabilities are $q_1q_2, q_1\bar{q_2}, \bar{q_1}q_3, \bar{q_1}\bar{q_3}$. Same for $p$. 
- We have $\zeta_2 = \left(\df{q_1q_2}{p_1p_2}, \df{q_1\bar{q_2}}{p_1\bar{p_2}}, \df{\bar{q_1}q_3}{\bar{p_1}p_3}, \df{\bar{q_1}\bar{q_3}}{\bar{p_1}\bar{p_3}}\right)$ and $\zeta_1 = \left(\df{q_1}{p_1}, \df{\bar{q_1}}{\bar{p_1}}\right)$.
:::

:::{.proposition #rdChangeMeasure name="change of measure"}
Given equivalent measures $\mbb P, \mbb Q$ and process $X_t$ adapted to $(\mca F_t)$, 
recall the Radon-Nikodym process $\zeta_t = \mbb E_{\mbb P} \left[\df{d\mbb Q}{d\mbb P} \bigg| \mca F_t\right]$ for the RN-derivative defined at time $T>t$, we have 
\[ 
    \mbb E_{\mbb Q} \left[
        X_t\mid \mca F_s 
    \right] = \mbb E_{\mbb P} \left[\zeta_s^{-1} \zeta_t X_t \mid \mca F_s\right] = \zeta_s^{-1} \mbb E_{\mbb P} \left[\zeta_t X_t \mid \mca F_s\right], \quad 0\leq s\leq t\leq T 
\] 

1. All of the involved quantities are processes. 
2. $\zeta_s^{-1}$ is extractable since it is known at time $s$. 
3. Think as: $\zeta_t X_t$ under $\mbb E_{\mbb P}$ converts the transition probabilities in $[0, t]$ to measure $\mbb Q$, but we over-compensated on the transition in $[0, s]$ since we've already conditioned on $\mca F_s$.  
:::

:::{.remark}
<span style="color:blue">
Density of processes along a path $\omega\in \Omega$ is defined as the density of having points $\mbf x$ at times $\mbf t$ of the process, in the mesh limit. 
</span>
:::

:::{.definition #wienerMeasure name="joint likelihood function for Brownian process"}
Take $x_0=t_0=0$. Consider $\{x_0, \dots, x_n\}\in \mbb R^n$ and increasing $\{t_0, \dots, t_n\}$. By condition 3 of Brownian definition \@ref(def:brownian), we have 
\[ 
    f_{\mbb P}^n(\mbf x, \mbf t) = \prod_{j=1}^n \df{1}{\sqrt{2\pi \Delta t_j}} \exp \left[ 
        -\df{(\Delta x_j)^2}{2\Delta t_j}
    \right]
\] 
The dense-mesh limit of this expression is also known as the **Wiener measure**. 
:::

:::{.definition name="continuous Radon-Nikodym derivative"}
Given equivalent measures $\mbb P, \mbb Q$ and path $\omega$, 
given a time mesh $\{t_0=0, t_1, \dots, t_n=T\}$, define $x_j= W_{t_j}(\omega)$. 
The RN-derivative up to time $T$ is 
\[ 
    \df{d\mbb Q}{d\mbb P}(\omega) = \lim_{n\to \infty} \df{f_{\mbb Q}^n(\mbf x, \mbf t)}{f_{\mbb P}^n(\mbf x, \mbf t)}
\] 
:::


## CMG theorem {#CMG -}

Consider a $\mbb P$-Brownian motion $W_t$ and define $\mbb Q$ up to horizon $T$ by 
\[ 
    \df{d\mbb Q}{d\mbb P}(\omega) = \exp \left(
        -\gamma W_T(\omega) - \df 1 2 \gamma^2 T 
    \right)
\] 

:::{.lemma name="identifying normals"}
A random variable $X\sim \mca N(\mu, \sigma^2)$ under $\mbb P$ iff 
\[ 
    \mbb E_{\mbb P} \left[
        \exp \left(
            \theta X
        \right)
    \right] = \exp \left(
        \theta \mu - \df 1 2 \theta^2 \sigma^2
    \right), \quad \forall \theta\in \R
\] 
:::

One can verify that the process $W_t$ is Brownian plus constant drift under $\mbb Q$. 

:::{.theorem name="Cameron-Martin-Girsanov theorem"}
If $W_t$ is a $\mbb P$-Brownian motion and $\gamma_t$ is a $\mca F$-previsible process such that 
\[ 
    \mbb E_{\mbb P} \exp \left(
        \df 1 2 \int_0^T \gamma_t^2\, dt
    \right) < \infty
\] 
then there exists $\mbb Q \sim \mbb P$ such that $\tilde W_t = W_t + \int_0^t \gamma_s\, ds$ is a $\mbb Q$-Brownian motion, and 
\[ 
    \df{d\mbb Q}{d\mbb P} = \exp \left(
        -\df 1 2 \int_0^T \gamma_t^2\, dt - \int_0^T \gamma_t\, dW_t
    \right)
\] 
**Conversely**, if $W_t$ is $\mbb P$-Brownian motion, and $\mbb Q\sim \mbb P$, then there exists previsible $\gamma_t$ such that 
\[ 
    \tilde W_t = W_t + \int_0^t \gamma_s\, ds \text{ is a $\mbb Q$-Brownian motion}
\] 
:::

:::{.remark name="applying CMG to change drift"}
Given a process $X$ given by $dX_t = \sigma_t\, dW_t + \mu_t\, dt$ where $W$ is $\mbb P$-Brownian motion. Suppose we wish to find measure $\mbb Q$ such that the drift of $X$ under $\mbb Q$ is $\mu_t\mapsto \nu_t$. First write 
\[ 
    dX_t = \sigma_t \left[
        dW_t + \left(\df{\mu_t - \nu_t}{\sigma_t}\right)_{\equiv \gamma_t}\, dt 
    \right] + \nu_t\, dt 
\] 
If $\gamma_t$ satisfies the CMG condition, then there exists a new measure such that $\tilde W_t = W_t + \int_0^t \gamma_s\, ds$ is a $\mbb Q$-Brownian motion, so that 
\[ 
    dX_t = \sigma_t\, d\tilde W_t + \nu_t\, dt 
\]  
:::

## Martingales {-}

:::{.definition name="martingale"}
A stochastic process $M_t$ is a $\mbb P$-**martingale** iff 
\[ 
    \mbb E_{\mbb P} |M_{\forall t}| < \infty\quad \text{and}\quad \mbb E_{\mbb P} \left[M_t \mid \mca F_s\right] = M_s, \quad \forall s\leq t
\] 

- Any trivial constant process is a martingale. 
- $\mbb P$-Brownian motion is $\mbb P$-martingale: 
\[ 
    \mbb E \left[
        W_t \mid \mca F_s 
    \right] = \Exp[W_s | \mca F_s] + \Exp[W_t - W_s | \mca F_s]_{=0} = W_s 
\] 
- Given a claim $X$ taking values at events at time $T$, the process $N_t = \Exp_{\mbb P}[X|\mca F_t]$ is a $\mbb P$-martingale. 
:::

The martingale representation theorem is the continuous generalization of the binomial representation theorem \@ref(thm:binRepTheorem). 

:::{.theorem #martRep name="martingale representation theorem"}
Given a $\mbb Q$-martingale $M_t$ with $\sigma_t\neq 0$ a.s., then for any other $\mbb Q$-martingale $N_t$, there exists a (essentially unique), previsible process $\phi_t$ such that $\int_0^t \phi_t^2 \sigma_t^2\, dt < \infty$ a.s. and 
\[ 
    N_t = N_0 + \int_0^t \phi_s\, dM_s 
\] 
:::

:::{.theorem #martingaleChar name="martingale characterization"}
If $X$ is a $\mbb P$-martingale subject to $\Exp \left(\int_0^T \sigma_s^2\, ds\right)^{1/2} < \infty$, then 
\[ 
    X \text{ is a $\mbb P$-martingale} \iff \mu_t = 0 \text{ a.s.}
\] 
:::

_Proof:_ In the forward direction, given $X_t$, consider a $\mbb P$-Brownian motion $W_t$. Apply theorem \@ref(thm:martRep) to obtain the SDE with zero drift: 
\[ 
    X_t = X_0 + \int_0^t \phi_s\, dW_s \implies dX_t = \phi_t\, dW_t
\]  
The converse is too difficult to prove here. 

:::{.theorem #expMartingaleChar name="exponential martingale characterization"}
For previsible $\sigma_t$, consider the process 
\[ 
    dX_t = \sigma_t X_t\, dW_t \iff X_t = X_0 \exp \left(
        \int_0^t \sigma_s\, dW_s - \df 1 2 \int_0^t \sigma_s^2\, ds 
    \right)
\] 
Then $\Exp \exp \left(\df 1 2 \int_0^T \sigma_s^2\, ds\right) < \infty \implies X_t$ is a $\mbb P$-martingale. 
:::