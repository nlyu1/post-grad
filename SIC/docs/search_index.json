[["index.html", "SIE Notes: Summer 2025 Preface", " SIE Notes: Summer 2025 Nicholas Lyu 2025-06-13 Preface These notes accompany the summer 2025 self-learning for the Securities Industry Exam (SIE). "],["discrete-models.html", "1 Discrete models Teaser: forward contracts Binomial branch model Binomial tree model Binomial tree pricing", " 1 Discrete models Central takeaways: Strong law (expectation) pricing is subjectively fair w.r.t. beliefs, while risk-free arbitrarge pricing is objective. Teaser: forward contracts A forward contract at price \\(K\\) allows the holder to buy an asset at a specified price at a future time for price \\(K\\). Assuming interest rate \\(r\\) so that cash grows as \\(e^{rt}\\), let \\(\\mathbf S_t\\) denote the price of the asset at time \\(t\\) Remark (strong law pricing). Using expectation calculus, the rational forward price is \\(\\mathbb{E}[S_t]\\). For a greater forward price, we can sell the contract and buy the asset. For a lower forward price, we can buy the contract and sell the asset. Remark (risk-free arbitrarge pricing). However, we claim that the forward price is \\(S_0 e^{rt}\\). For greater forward price \\(K\\), we lend \\(S_0\\) to buy the asset right now, sell a contract, and deliver the asset at time \\(t\\), using the proceeds \\(K\\) to pay the loan \\(S_0e^{rt}\\), gaining \\(K-S_0e^{rt}\\). Net: short contract, long stock, short cash. For lower forward price \\(K\\), we borrow a stock, sell it immediately for \\(S_0\\), and buy a contract right now. At time \\(t\\), we buy the stock for \\(K\\) to pay off the loan, gaining \\(S_0e^{rt} - K\\). Note that there are three parties: us, contract counterparty, and stock counterparty. Payoffs below are given at time \\(t\\). Party \\(K&gt;S_0e^{rt}\\) \\(K&lt;S_0e^{rt}\\) Me stock, cash, contract. Payoff: \\(K-S_0e^{rt}&gt;0\\) stock, cash, contract. Payoff: \\(S_0e^{rt}-K&gt;0\\). Stock cpty stock. Payoff: \\(S_0e^{rt}-S_t\\) stock. Payoff: \\(S_t-S_0e^{rt}\\) Contract cpty contract. Payoff: \\(K-S_t\\) contract. Payoff: \\(S_t-K\\) A few salient points: The arbitrarge party is risk-free. The net loss \\(-|K-S_0e^{rt}|\\) is always split between the stock and contract counterparties. This does not contradict the fact that strong law pricing is fair in expectation if \\(K=\\mathbb{E}[S_t]\\). Suppose \\(\\mathbb{E}[S_t]&gt;S_0e^{rt}\\) (for example, for risk premium), and that this is known by the contract counterparty. They will short the contract at \\(K=S_0e^{rt}\\), and the stock counterparty will lose in expectation. Suppose \\(\\mathbb{E}[S_t]&lt;S_0e^{rt}\\) and that this is known by the contract counterparty, they will long the contract and gain \\(K-S_0e^{rt}&gt;0\\). The stock counterparty will lose in expectation. Assuming rational behavior, trade only happens when stock and contract counterparties disagree on the relative size of \\(\\mathbb{E}[S_t]\\) compared to \\(K\\)). Binomial branch model Assume a simple model where: Stock has price \\(s_1\\) at \\(t=0\\), and at \\(t=1\\) goes up to \\(\\mathbf S_1=s_3\\) w.p. \\(p\\) or down to \\(\\mathbf S_2=s_2\\) w.p. \\(\\bar p\\). Compound interest rate \\(r\\). Question: is it possible to construct a portfolio that pays \\(f(3)\\) when \\(\\mathbf S_1=s_3\\) and \\(f(2)\\) when \\(\\mathbf S_2=s_2\\)? Consider a portfolio \\(\\phi\\) of stocks and \\(\\psi\\) of cash worth \\(\\phi s_1 + \\psi\\) at the beginning. At \\(t=1\\), the portfolio is worth \\(\\phi s_3 + \\psi e^{r}\\) if \\(\\mathbf S_1=s_3\\) and \\(\\phi s_2 + \\psi e^{r}\\) if \\(\\mathbf S_2=s_2\\). Solve for the following system of equations, non-degenerate when stock is different from bond. \\[ \\begin{cases} \\phi s_2 + \\psi e^{r} = f(2) \\\\ \\phi s_3 + \\psi e^{r} = f(3) \\end{cases} \\] This yields the fair price (at \\(t=0\\))\\(V=s_1\\phi^*+\\psi^*\\) of the derivative with payoff \\(f\\). \\[ V = e^{-r}(\\bar q f_2 + q f_3), \\quad q = \\dfrac{s_1 e^{rt} - s_2}{s_3 - s_2}. \\] Looking at \\(q\\), w.l.o.g. assume \\(s_3&gt;s_2\\). This suggests that the risk-free strike price \\(V\\) is a discounted expectation w.r.t. some measure \\(q\\), of its possible payoffs. Note that the measure \\(q\\) is not the same as the probability \\(p\\) of the realizations. For \\(q\\leq 0\\), we have \\(s_3&gt;s_2&gt;s_1e^{rt}\\). This means that the stock strictly dominates cash (even in the worst payoff). For \\(q\\geq 1\\), rearranging yields \\(s_1 e^r \\geq s_3&gt;s_2\\), making cash dominate the stock. Binomial tree model Stock price starts at \\(s_1\\) at \\(t=0\\). If the stock price \\(\\mathbf S_t=s_j\\), then \\(\\mathbf S_{t+1}\\) is \\(s_{2j+1}\\) w.p. \\(p_j\\) or \\(s_{2j}\\) w.p. \\(\\bar p_j\\). The cash bond has, for simplicity, constant interest rate \\(r\\). Note that in the tree model, the node index \\(j\\) is bijective with the root-to-node path. Thus, a derivative that specifies price at each node is equivalent to a derivative that specifies price for each path. Remark (risk-neutral pricing for tree model). Use backward induction to price the tree-model derivative: the value assigned to each node effectively says: “if I have this much money at this node, I can construct a portfolio that replicates the derivative payoffs which starts at this node”. Some preliminary definitions for the binomial representation theorem: The set of stock values, and the set of paths, is a process \\(S\\). The set of probabilities is a measure \\(\\mathbb P\\) or \\(\\mathbb Q\\). A filtration \\((\\mathcal F_j)\\) is the history of the process up to time \\(j\\) (ordered list of visited nodes). A claim \\(X\\) on the tree is a function of the filtration at some time horizon \\(T\\); it assigns a claim value to each path. Denote the conditional expectation operator \\(\\mathbb E_{\\mathbb Q}(\\cdot\\, | \\mathcal F_j)\\). A previsible process \\(\\phi\\) is a process whose value at any given node at tick \\(j\\) is only dependent upon its history up to that point. Definition 1.1 (martingale) A process \\(S\\) is a martingale w.r.t. \\(\\mathbb P\\) and filtration \\((\\mathcal F_j)\\) if \\[ \\mathbb E_{\\mathbb P}(S_k|\\mathcal F_j) = S_j, \\quad \\forall j\\leq k \\] In other words, the future EV of the process under \\(\\mathbb P\\), conditional on its history up to time \\(j\\), is equal to the process’s value at time \\(j\\). One salient example of a martingale: Proposition 1.1 (conditional expectation extension) For any claim \\(X\\) and measure \\(\\mathbb P\\), the process \\(\\mathbb E_{\\mathbb P}(X|\\mathcal F_j)\\) is a martingale. Proof: Simply note that for \\(k\\geq j\\), by the law of total expectation, we have \\[ \\mathbb E_{\\mathbb P} \\left[ \\mathbb E_{\\mathbb P}(X|\\mathcal F_k) \\big| \\mathcal F_j \\right] = \\mathbb E_{\\mathbb P}(X|\\mathcal F_j) \\] Theorem 1.1 (binomial representation theorem) Suppose there exists \\(\\mathbb Q\\) such that the binomial price process \\(S\\) is a \\(\\mathbb Q\\)-martingale. Then, for any other \\(\\mathbb Q\\)-martingale \\(N\\), there exists a previsible process \\(\\phi\\) such that \\[ N_j = N_0 + \\sum_{k=1}^j \\phi_k \\Delta S_k \\] where \\(\\Delta S_k = S_k - S_{k-1}\\) and \\(\\phi_j\\) is the value of \\(\\phi\\) at the appropriate node at time \\(j\\). Note that \\(N_0\\) is a fixed value, and that based on the definition of \\(\\Delta S\\), the process value \\(\\phi_k\\) is computable at time \\(k-1\\). In other words, any \\(\\mathbb Q\\)-martingale is equivalent (up to constant) to the accumulation of a previsible adjusting process (this would inform our purchase of the stock), times the stock price change, if the stock price is a \\(\\mathbb Q\\)-martingale. \\(\\phi_k\\) provides for the degrees of freedom to adjust the magnitude of the process changes in a previsible manner, and there is no price-dependent term due to the martingale property. The martingale property eliminates the price-dependent “constant” degrees of freedom, leaving only the previsible, scaling degrees of freedom which are only dependent upon the price change. The scaling process \\(\\phi\\) denotes the previsible stock allocation. Proof: For the simple \\(2\\)-branch case, denote \\(s_{\\mathrm{now}}, s_{\\mathrm{up}}, s_{\\mathrm{down}}\\) and \\(n_{\\mathrm{now}}, n_{\\mathrm{up}}, n_{\\mathrm{down}}\\), solve for \\[ n_{\\mathrm{up}} = N_0 + \\phi_1 (s_{\\mathrm{up}} - s_{\\mathrm{now}}), \\quad n_{\\mathrm{down}} = N_0 + \\phi_1 (s_{\\mathrm{down}} - s_{\\mathrm{now}}) \\] The scaling \\(\\phi_1\\) will be \\((n_{\\mathrm{up}} - n_{\\mathrm{down}}) / (s_{\\mathrm{up}} - s_{\\mathrm{down}})\\). Inductively, consider \\[ \\Delta N_j = \\phi_j \\Delta S_j + k \\] where \\(\\phi_j\\) is the ratio of the up-down difference of \\(N\\) versus \\(S\\) at the node under consideration at time \\(j\\). Next, take the expectation of both sides and use the martingale property \\[ \\mathbb E_{\\mathbb Q} \\left[ \\Delta N_j \\big| \\mathcal F_{j-1} \\right]_{=0} = \\mathbb E_{\\mathbb Q} \\left[ \\phi_j \\Delta S_j\\big| \\mathcal F_{j-1} \\right]_{=0} + k \\implies k = 0 \\] Binomial tree pricing Assume in full generality a stock process \\(S\\) and a bond process \\(B\\) (with \\(B_0=1\\)). Fixing claim \\(X\\) and time horizon \\(T\\): First, annul the time growth of money: define the discounted claim \\(B_T^{-1}X\\) and the discounted stock process \\(Z_j=(B_j^{-1}S_j)\\). Assumption : in a sensible world, there is a measure \\(\\mathbb Q\\) such that the discounted stock process \\(Z_j\\) is a \\(\\mathbb Q\\)-martingale (see discussion in branch case). This is known as the fundamental theorem of asset pricing and provable by the separating hyperplane theorem, which introduces the existence of a positive linear functional. Extend the discounted claim \\(B_T^{-1}X\\) to a \\(\\mathbb Q\\)-martingale \\(E\\) (proposition 1.1). Write \\(E_j = E_0 + \\sum_{k=1}^j \\phi_k \\Delta Z_k\\) by theorem 1.1. Here \\(E_0 = \\mathbb E_{\\mathbb Q}(B_T^{-1}X) = \\mathbb E_{\\mathbb Q}(E)\\). Construction as follows: at time \\(j\\), but portfolio \\(\\Pi_j\\) consisting of \\(\\phi_{j+1}\\) units of stock and \\(\\psi_{j+1} = E_j - \\phi_{j+1} Z_j\\) units of cash. At time \\(0\\), \\(\\Pi_0\\) is worth \\(\\phi_1 S_0 + \\psi_1 = E_0\\). The value of \\(\\Pi_{\\forall j}\\) (from the POV of \\(t=0\\)) is always \\(E_j\\). At time \\(1\\), \\(\\Pi_0\\) is worth \\(\\phi_1 S_1 + \\psi_1 = E_0 + \\phi_1 \\Delta Z_1 = E_1\\). This is enough to finance \\(\\Pi_1\\). The strategy \\((\\psi, \\phi)\\) defined as such is self-financing, in that holding \\(\\Pi_t\\) from \\(t\\mapsto t+1\\) is sufficient to finance \\(\\Pi_{t+1}\\). Theorem 1.2 (claim pricing formula) By the risk-free construction, the value at tick-time \\(j\\) of a claim \\(X\\) maturing at some time \\(T\\) is \\[ \\mathbb E_{\\mathbb Q}\\left[ (B_j B_T^{-1}) X \\big| \\mathcal F_j \\right] \\] In other words, it is the conditional expectation of the cash-discounted claim w.r.t. the martingale measure \\(\\mathbb Q\\) for the underlying. The value above is observed at time \\(j\\). Note that \\(B_j B_T^{-1}\\) is the normalized discount factor w.r.t. this value observation. Example 1.1 (trivial example) Consider cash without interest and a stock priced at \\(1\\). At the end, the stock is worth either \\(2\\) or \\(0.5\\). What is the worth of a bet which pays \\(1\\) if the stock goes up? The ratio of (the up-down difference of the claim) to (the up-down difference of the stock) is \\(1/(3/2)=2/3\\). To fulfill the claim when the stock goes up, we need to hold \\(1 - 2/3\\cdot 2 = -1/3\\) of cash. Thet net portfolio is then \\((-1/3, 2/3)\\) of cash and stock, worth \\(1/3\\) at the beginning. "],["continuous-models.html", "2 Continuous models Preliminaries Brownian process Stochastic calculus Change of process measure CMG theorem Martingales", " 2 Continuous models Preliminaries Definition 2.1 (stochastic process) Given a probability space \\((\\Omega, \\mathcal F, \\mathbb P)\\), where \\(\\Omega\\) is the sample space. \\(\\mathcal F\\) is a \\(\\sigma\\)-algebra of events to which probabilities can be assigned. \\(\\mathbb P\\) is a probability measure on \\(\\mathcal F\\). A random variable is a measurable function \\(X: \\Omega \\to \\mathbb R\\). The \\(\\sigma\\)-algebra generated by \\(X\\) is \\(\\sigma(X) = \\{X^{-1}(B) \\mid B\\in \\mathbb B(\\mathbb R)\\}\\subseteq\\mathcal F\\); it encodes the information about \\(\\Omega\\) that’s revealable by \\(X\\); definition extends naturally to vector-valued random variables (or collection of random variables). \\(X_1, \\dots, X_n\\) are independent if \\(\\sigma(X_1), \\dots, \\sigma(X_n)\\) are independent: \\[ P(\\{X_j\\in A_j\\}) = \\prod_{j=1}^n P(X_j\\in A_j) \\] Independence of random variables are defined analogously. Let \\(T\\subseteq \\mathbb R_+\\) be the time index; a real-valued stochastic process is a measurable map \\[ X: \\Omega \\times T \\to \\mathbb R. \\] so that \\(X_{\\forall t\\in T}\\) is a random variable. A filtration \\((\\mathcal F_{t\\in T})\\) is an increasing family of \\(\\sigma\\)-algebras satisfying \\(\\mathcal F_0\\subseteq \\mathcal F_{0\\leq s\\leq t}\\subseteq \\mathcal F_t\\subseteq \\mathcal F\\). Definition 2.2 (filtration and processes) The natural filtration of a stochastic process \\(X\\) is the filtration \\((\\mathcal F_t)\\) defined by \\[ \\mathcal F_t = \\sigma(X_s \\mid s\\leq t). \\] A stochastic process is adapted to a filtration \\((\\mathcal F_t)\\) if \\(X_t\\) is \\(\\mathcal F_t\\)-measurable for all \\(t\\in T\\); this asks that the value of \\(X_t\\) is uniquely determined by distinguishable sample partitions known up to time \\(t\\). Brownian process By intuition, a continuous process should be continuous, variable across time, and real-valued. Example 2.1 (tentative random walk) Given a positive integer \\(n\\), define the binomial process \\(W_n(t)\\) with \\(W_n(0) = 0\\). Layer spacing \\(\\delta = 1/n\\). Up and down jumps with equal size \\(1/\\sqrt n\\). Measure \\(\\mathbb P\\) uniform between up and down jumps. In other words, given a sequence of i.i.d. \\(X_j\\) with \\(\\pm 1\\), define \\[ W_n\\left(\\dfrac j n\\right) = W_n\\left(\\dfrac{j-1} n\\right) + \\dfrac{1}{\\sqrt n} X_j \\] The definition of \\(W_n(1)\\) is (second argument denoting standard deviation): \\[ W_n(t) = \\dfrac{\\sum_{j=1}^{nt} X_j}{\\sqrt n}\\sim \\mathcal N\\left( 0, \\sqrt t \\right) \\] Future movements away from a position are independent of the history up to that point. \\(W_n(s+t)-W_n(s)\\sim \\mathcal N(0, \\sqrt t)\\). Definition 2.3 (Brownian process) A process \\((W_{t\\geq 0})\\) is a \\(\\mathbb P\\)-Brownian process iff \\(W_t\\) is continuous with \\(W_0=0\\). Under \\(\\mathbb P\\), the random variable \\(W_t\\sim \\mathcal N(0, t)\\). The increment \\(W_{s+t} - W_s\\sim \\mathcal N(0, t)\\) under \\(\\mathcal P\\) and is independent of \\(\\mathcal F_s\\). An exponential Brownian process is defined by \\(X_t = \\exp(\\sigma W_t + \\mu t)\\). Definition 2.4 (standard Brownian process) The standard Brownian process (also known as the Wiener process) consists of the following components: Sample space \\(\\Omega\\) : \\(C_0([0, \\infty)\\to \\mathbb R)\\) \\(\\sigma\\)-algebra generated by the uniform topology; makes “evaluate the path at finitely many points” measurable. Probability measure \\(\\mathbb P:\\Omega\\to [0, 1]\\) given by the Wiener measure (see 2.7). Process : \\(W_t(\\omega) = \\omega(t)\\) for all \\(t\\geq 0\\). It is simply the coordinate map; the standard Brownian process \\(W_t\\) is canonical due to the canonical coordinate-map process. Remark. A Brownian process is a process-measure pair! Alternative Brownian processs might exist (see CMG theorem)! A standard Brownian process with previsible drift \\(W_t+\\mu_t\\) is not Brownian under the Wiener measure, but is Brownian under a tilted measure. Stochastic calculus Recall the classical, Newtonian differential notations: If \\(f_t\\) and \\(\\tilde f_t\\) are differentiable, agreeing at \\(0\\), and \\(df_t = d\\tilde f_t\\) (here \\(df_t\\) overloads for the derivative function), then \\(f_t = \\tilde f_t\\). Given differentiable \\(f\\), there is a unique drift \\(\\mu_t\\) such that \\(f_t = f_0 + \\int_0^t \\mu_s\\, ds\\) for all \\(t\\). Remark. The differential notation \\(df = \\mu(f, t)\\, dt\\) is a recipe for building differentiable functions from a drift function. Intuition: differentiable functions zoom to tangent lines, while Brownian process zooms to Brownian process; this inspires the following definition: Definition 2.5 (continuous Itô processes, diffusion) A stochastic process (more restrictive definition) \\(X_t\\) is a continuous process such that \\[\\begin{align} dX_t &amp;= \\sigma_t\\, dW_t + \\mu_t\\, dt \\\\ X_t &amp;= X_0 + \\int_0^t \\sigma_s\\, dW_s + \\int_0^t \\mu_s\\, ds \\end{align}\\] where \\(\\sigma, \\mu\\) are \\(\\mathcal F\\)-previsible processes such that \\(\\int_0^t (\\sigma_s^2 + |\\mu_s|)\\, ds &lt; \\infty\\) a.s. When \\(\\sigma, \\mu\\) are only dependent on \\(X_t\\) (instead of the full history), every strong solution is a diffusion. Remark (justification for Brownian process as fundamental building block). Brownian process is the continuous limit of equi-probable binary branching processes. Any “reasonable” branching can be approximated by an affine transformation of such branching, with offset and scale given by \\(\\mu_t\\) and \\(\\sigma_t\\), respectively. Any continuous model requiring time-homogeneous, independent shocks and appropriate scale limit dictates Brownian process as the stochastic building block. Consider \\(d f(W_t)\\) for \\(f(x)=x^2\\). Newtonian intuition suggests \\(d(W_t^2) = 2W_t\\, dW_t\\), but this should be checked by \\[ \\text{whether } W_t^2 = \\int_0^t d(W_s^2) =^? 2\\int_0^t W_s\\, dW_s \\] Define the RHS integral by approximation; note that the square bracket term has mean \\(0\\) and is independent of \\(W_{jt/n}\\). \\[ 2\\int_0^t W_s\\, dW_s \\approx 2\\sum_{j=0}^{n-1} W\\left(\\dfrac{jt}{n}\\right)\\left[W\\left(\\dfrac{(j+1)t}{n}\\right) - W\\left(\\dfrac{jt}{n}\\right)\\right]_{=0} = 0 \\] But \\(W_t^2\\) does not have zero mean, so something is wrong here. Consider the Taylor expansion \\[ df(W_t) = f&#39;(W_t)\\, dW_t + \\dfrac 1 2 f&#39;&#39;(W_t)\\, (dW_t)^2 + \\dots \\] In Newtonian differentials, \\((dW_t)^2 = 0\\), so are higher-order terms. However, recall that \\(W_t - W_s\\sim \\mathcal N(0, t-s) = \\sqrt{t-s}Z\\) and are independent for disjoint partitions: \\[\\begin{align} \\int_0^t (dW_t)^2 &amp;\\approx \\sum_{j=1}^n \\left( W_{tj/n} - W_{t(j-1)/n} \\right)^2 \\\\ &amp;= \\sum_{j=1}^n \\left(Z_j \\sqrt{t/n}\\right)^2 = t \\sum_{j=1}^n \\dfrac{Z_j^2}{n}, \\quad Z_j\\sim \\mathcal N(0, 1) \\text{ i.i.d.} \\\\ &amp;= t \\text{ by law of large numbers} \\\\ (dW_t)^2 &amp;= dt \\end{align}\\] Recall that \\(\\mathbb{E}[Z^2] = \\mathrm{Var}(Z) + \\mathbb{E}[Z]^2 = 1\\). The higher orders \\((dW_t)^{k\\geq 3}\\) are negligible. Intuitively, Brownian increments are of order \\(\\sqrt{dt}\\). Definition 2.6 (Itô's formula) Given \\(dX_t = \\sigma_t\\, dW_t + \\mu_t\\, dt\\) and \\(f\\) deterministic twice continuously differentiable: \\[ df(X_t) = \\left[ \\sigma_t f&#39;(X_t) \\right]\\, dW_t + \\left[ \\mu_t f&#39;(X_t) + \\dfrac 1 2 \\sigma_t^2 f&#39;&#39;(X_t) \\right]\\, dt \\] For example, substituting \\(f(x)=x^2\\) yields \\[ d(W_t^2) = 2W_t\\, dW_t + dt \\] Note that while \\(dX_t = \\sigma\\, dW_t + \\mu\\, dt \\implies X_t = X_0 + \\sigma W_t + \\mu t\\), we have the more general \\[ dX_t = \\sigma_t\\, dW_t + \\mu_t\\, dt \\implies X_t = X_0 + \\int_0^t \\sigma_s\\, dW_s + \\int_0^t \\mu_s\\, ds \\] The stochastic integral \\(\\int_0^t \\sigma_s\\, dW_s \\neq \\left(\\int_0^t \\sigma_s\\, ds \\right)W_t\\) in general. Example 2.2 (common differentials) Consider the quadratic and the exponential: Let \\(dX_t = \\sigma_t\\, dW_t + \\mu_t\\, dt\\), then \\[ d(X_t^2) = \\left(2\\sigma_t X_t\\right) \\, dW_t + \\left( 2 \\mu_t X_t + \\sigma_t^2 \\right)\\, dt \\] \\(d e^{W_t} = e^{W_t}\\, dW_t + \\dfrac 1 2 e^{W_t}\\, dt\\). Example 2.3 (exponential diffusion equation with constant volatility) \\[ dY_t = Y_t\\left(\\sigma_t \\, dW_t + \\mu_t\\, dt\\right) \\implies Y_t = Y_0 \\exp \\left[ \\int_0^t \\sigma_s\\, dW_s + \\int_0^t \\left( \\mu_s - \\dfrac 1 2 \\sigma_s^2 \\right)\\, ds \\right] \\] Let \\(Y_t = f(X_t)\\) with \\(dX_t = \\sigma_t\\, dW_t + \\mu_t\\, dt\\), matching yields equations \\[ \\hat \\sigma_t f&#39;(X_t) = \\sigma_t f(X_t), \\quad \\hat \\mu_t f&#39;(X_t) + \\dfrac 1 2 \\hat \\sigma_t^2 f&#39;&#39;(X_t) = f(X_t) \\mu_t \\] Solve for \\(\\hat \\sigma_t, f(X_t)\\), and \\(\\hat \\mu_t\\): \\[ \\hat \\sigma_t = \\sigma_t, \\quad f(X_t) = e^{C X_t}, \\quad \\hat \\mu_t + \\dfrac 1 2 \\hat \\sigma_t^2 = \\mu_t \\implies \\hat \\mu_t = \\mu_t - \\dfrac 1 2 \\sigma_t^2 \\] This gives \\(dY_t = d f(X_t)\\), where the RHS is no longer dependent upon \\(Y_t\\). \\[\\begin{align} Y_t &amp;= \\int_0^t dY_s = \\int_0^t Y_s\\left(\\sigma_s \\, dW_s + \\mu_s\\, ds\\right) \\\\ &amp;= \\int_0^t d f(X_s) = f(X_t) \\\\ &amp;= C\\exp \\left[ \\int_0^t \\sigma_s\\, dW_s + \\int_0^t \\left( \\mu_s - \\dfrac 1 2 \\sigma_s^2 \\right)\\, ds \\right], \\quad C=Y_0 \\end{align}\\] Proposition 2.1 (product rule) When \\(X_t, Y_t\\) are adapted to the same Brownian process \\[ dX_t = \\sigma_t\\, dW_t + \\mu_t\\, dt, \\quad dY_t = \\rho_t\\, dW_t + \\nu_t\\, dt \\] We have \\(d(X_tY_t) = X_t\\, dY_t + Y_t\\, dX_t + (dX_t)(dY_t)\\). \\[\\begin{align} d(2 X_t Y_t) &amp;= d(X_t + Y_t)^2 - d(X_t^2) - d(Y_t^2) \\\\ &amp;= \\left[ 2(\\sigma_t + \\rho_t) (X_t + Y_t) \\, dW_t + \\left( 2 (\\mu_t + \\nu_t) (X_t + Y_t) + (\\sigma_t + \\rho_t)^2 \\right)\\, dt \\right] \\\\ &amp;\\quad - \\left[ 2\\sigma_t X_t \\, dW_t + \\left( 2 \\mu_t X_t + \\sigma_t^2 \\right)\\, dt \\right] \\\\ &amp;\\quad - \\left[ 2\\rho_t Y_t \\, dW_t + \\left( 2 \\nu_t Y_t + \\rho_t^2 \\right)\\, dt \\right] \\\\ &amp;= 2 \\left( \\sigma_t Y_t + \\rho_t X_t \\right)\\, dW_t + \\left( 2\\mu_t Y_t + 2\\nu_t X_t + 2 \\sigma_t \\rho_t \\right)\\, dt \\\\ X_t\\, dY_t + Y_t\\, dX_t &amp;= X_t \\left( \\rho_t\\, dW_t + \\nu_t\\, dt \\right) + Y_t \\left( \\sigma_t\\, dW_t + \\mu_t\\, dt \\right) \\\\ &amp;= d(X_tY_t) - \\sigma_t \\rho_t\\, dt \\end{align}\\] This yields the product rule by noting that \\((dX_t)(dY_t) = \\sigma_t \\rho_t\\, dt\\) (\\(dW_t^2 = dt\\) and \\(dt^2 = dt\\, dW_t = 0\\)). Also note that we cannot apply Ito directly to \\(X_t\\mapsto X_tY_t\\) because this is not a deterministic function. Change of process measure Define by \\(\\zeta_t\\) the Radon-Nikodym derivative taken up to the horizon \\(t\\): i.e. it is the likelihood-ratio map measurable by \\(\\mathcal F_t\\). Fixing a horizon \\(T\\) and calculate the Radon-Nikodym derivative \\(d\\mathbb Q/d\\mathbb P\\) at time \\(T\\), we have \\[ \\zeta_t = \\mathbb E_{\\mathbb P} \\left[ \\dfrac{d\\mathbb Q}{d\\mathbb P} \\bigg| \\mathcal F_t \\right], \\quad \\forall t\\leq T \\] Remark. The expectation above w.r.t. \\(\\mathcal F_t\\) makes sure that \\(\\zeta_t\\) is adapted to the information available up to time \\(t\\) only. In the discrete picture, this expectation equivalently puts a unique value on each node at time \\(t\\). The expectation is taken w.r.t. \\(\\mathbb P\\) because \\(\\mathbb Q\\) is in the numerator (so conditionals sum to \\(1\\)), while conditionals in \\(\\mathbb P\\) are in the denominator. See example below. Example 2.4 (simple illustration) Consider two 2-level binary-tree processes \\(\\mathbb Q, \\mathbb P\\) with the first level parameterized by \\(q_1\\), the second by \\(q_2, q_3\\) respectively; same for \\(p\\). Under \\(\\mathbb Q\\), the tail probabilities are \\(q_1q_2, q_1\\bar{q_2}, \\bar{q_1}q_3, \\bar{q_1}\\bar{q_3}\\). Same for \\(p\\). We have \\(\\zeta_2 = \\left(\\dfrac{q_1q_2}{p_1p_2}, \\dfrac{q_1\\bar{q_2}}{p_1\\bar{p_2}}, \\dfrac{\\bar{q_1}q_3}{\\bar{p_1}p_3}, \\dfrac{\\bar{q_1}\\bar{q_3}}{\\bar{p_1}\\bar{p_3}}\\right)\\) and \\(\\zeta_1 = \\left(\\dfrac{q_1}{p_1}, \\dfrac{\\bar{q_1}}{\\bar{p_1}}\\right)\\). Proposition 2.2 (change of measure) Given equivalent measures \\(\\mathbb P, \\mathbb Q\\) and process \\(X_t\\) adapted to \\((\\mathcal F_t)\\), recall the Radon-Nikodym process \\(\\zeta_t = \\mathbb E_{\\mathbb P} \\left[\\dfrac{d\\mathbb Q}{d\\mathbb P} \\bigg| \\mathcal F_t\\right]\\) for the RN-derivative defined at time \\(T&gt;t\\), we have \\[ \\mathbb E_{\\mathbb Q} \\left[ X_t\\mid \\mathcal F_s \\right] = \\mathbb E_{\\mathbb P} \\left[\\zeta_s^{-1} \\zeta_t X_t \\mid \\mathcal F_s\\right] = \\zeta_s^{-1} \\mathbb E_{\\mathbb P} \\left[\\zeta_t X_t \\mid \\mathcal F_s\\right], \\quad 0\\leq s\\leq t\\leq T \\] All of the involved quantities are processes. \\(\\zeta_s^{-1}\\) is extractable since it is known at time \\(s\\). Think as: \\(\\zeta_t X_t\\) under \\(\\mathbb E_{\\mathbb P}\\) converts the transition probabilities in \\([0, t]\\) to measure \\(\\mathbb Q\\), but we over-compensated on the transition in \\([0, s]\\) since we’ve already conditioned on \\(\\mathcal F_s\\). Remark. Density of processes along a path \\(\\omega\\in \\Omega\\) is defined as the density of having points \\(\\mathbf x\\) at times \\(\\mathbf t\\) of the process, in the mesh limit. Definition 2.7 (joint likelihood function for Brownian process) Take \\(x_0=t_0=0\\). Consider \\(\\{x_0, \\dots, x_n\\}\\in \\mathbb R^n\\) and increasing \\(\\{t_0, \\dots, t_n\\}\\). By condition 3 of Brownian definition 2.3, we have \\[ f_{\\mathbb P}^n(\\mathbf x, \\mathbf t) = \\prod_{j=1}^n \\dfrac{1}{\\sqrt{2\\pi \\Delta t_j}} \\exp \\left[ -\\dfrac{(\\Delta x_j)^2}{2\\Delta t_j} \\right] \\] The dense-mesh limit of this expression is also known as the Wiener measure. Definition 2.8 (continuous Radon-Nikodym derivative) Given equivalent measures \\(\\mathbb P, \\mathbb Q\\) and path \\(\\omega\\), given a time mesh \\(\\{t_0=0, t_1, \\dots, t_n=T\\}\\), define \\(x_j= W_{t_j}(\\omega)\\). The RN-derivative up to time \\(T\\) is \\[ \\dfrac{d\\mathbb Q}{d\\mathbb P}(\\omega) = \\lim_{n\\to \\infty} \\dfrac{f_{\\mathbb Q}^n(\\mathbf x, \\mathbf t)}{f_{\\mathbb P}^n(\\mathbf x, \\mathbf t)} \\] CMG theorem Consider a \\(\\mathbb P\\)-Brownian motion \\(W_t\\) and define \\(\\mathbb Q\\) up to horizon \\(T\\) by \\[ \\dfrac{d\\mathbb Q}{d\\mathbb P}(\\omega) = \\exp \\left( -\\gamma W_T(\\omega) - \\dfrac 1 2 \\gamma^2 T \\right) \\] Lemma 2.1 (identifying normals) A random variable \\(X\\sim \\mathcal N(\\mu, \\sigma^2)\\) under \\(\\mathbb P\\) iff \\[ \\mathbb E_{\\mathbb P} \\left[ \\exp \\left( \\theta X \\right) \\right] = \\exp \\left( \\theta \\mu - \\dfrac 1 2 \\theta^2 \\sigma^2 \\right), \\quad \\forall \\theta\\in \\mathbb R \\] One can verify that the process \\(W_t\\) is Brownian plus constant drift under \\(\\mathbb Q\\). Theorem 2.1 (Cameron-Martin-Girsanov theorem) If \\(W_t\\) is a \\(\\mathbb P\\)-Brownian motion and \\(\\gamma_t\\) is a \\(\\mathcal F\\)-previsible process such that \\[ \\mathbb E_{\\mathbb P} \\exp \\left( \\dfrac 1 2 \\int_0^T \\gamma_t^2\\, dt \\right) &lt; \\infty \\] then there exists \\(\\mathbb Q \\sim \\mathbb P\\) such that \\(\\tilde W_t = W_t + \\int_0^t \\gamma_s\\, ds\\) is a \\(\\mathbb Q\\)-Brownian motion, and \\[ \\dfrac{d\\mathbb Q}{d\\mathbb P} = \\exp \\left( -\\dfrac 1 2 \\int_0^T \\gamma_t^2\\, dt - \\int_0^T \\gamma_t\\, dW_t \\right) \\] Conversely, if \\(W_t\\) is \\(\\mathbb P\\)-Brownian motion, and \\(\\mathbb Q\\sim \\mathbb P\\), then there exists previsible \\(\\gamma_t\\) such that \\[ \\tilde W_t = W_t + \\int_0^t \\gamma_s\\, ds \\text{ is a $\\mathbb Q$-Brownian motion} \\] Remark (applying CMG to change drift). Given a process \\(X\\) given by \\(dX_t = \\sigma_t\\, dW_t + \\mu_t\\, dt\\) where \\(W\\) is \\(\\mathbb P\\)-Brownian motion. Suppose we wish to find measure \\(\\mathbb Q\\) such that the drift of \\(X\\) under \\(\\mathbb Q\\) is \\(\\mu_t\\mapsto \\nu_t\\). First write \\[ dX_t = \\sigma_t \\left[ dW_t + \\left(\\dfrac{\\mu_t - \\nu_t}{\\sigma_t}\\right)_{\\equiv \\gamma_t}\\, dt \\right] + \\nu_t\\, dt \\] If \\(\\gamma_t\\) satisfies the CMG condition, then there exists a new measure such that \\(\\tilde W_t = W_t + \\int_0^t \\gamma_s\\, ds\\) is a \\(\\mathbb Q\\)-Brownian motion, so that \\[ dX_t = \\sigma_t\\, d\\tilde W_t + \\nu_t\\, dt \\] Martingales Definition 2.9 (martingale) A stochastic process \\(M_t\\) is a \\(\\mathbb P\\)-martingale iff \\[ \\mathbb E_{\\mathbb P} |M_{\\forall t}| &lt; \\infty\\quad \\text{and}\\quad \\mathbb E_{\\mathbb P} \\left[M_t \\mid \\mathcal F_s\\right] = M_s, \\quad \\forall s\\leq t \\] Any trivial constant process is a martingale. \\(\\mathbb P\\)-Brownian motion is \\(\\mathbb P\\)-martingale: \\[ \\mathbb E \\left[ W_t \\mid \\mathcal F_s \\right] = \\mathbb{E}[W_s | \\mathcal F_s] + \\mathbb{E}[W_t - W_s | \\mathcal F_s]_{=0} = W_s \\] Given a claim \\(X\\) taking values at events at time \\(T\\), the process \\(N_t = \\mathbb{E}_{\\mathbb P}[X|\\mathcal F_t]\\) is a \\(\\mathbb P\\)-martingale. The martingale representation theorem is the continuous generalization of the binomial representation theorem 1.1. Theorem 2.2 (martingale representation theorem) Given a \\(\\mathbb Q\\)-martingale \\(M_t\\) with \\(\\sigma_t\\neq 0\\) a.s., then for any other \\(\\mathbb Q\\)-martingale \\(N_t\\), there exists a (essentially unique), previsible process \\(\\phi_t\\) such that \\(\\int_0^t \\phi_t^2 \\sigma_t^2\\, dt &lt; \\infty\\) a.s. and \\[ N_t = N_0 + \\int_0^t \\phi_s\\, dM_s \\] Theorem 2.3 (martingale characterization) If \\(X\\) is a \\(\\mathbb P\\)-martingale subject to \\(\\mathbb{E}\\left(\\int_0^T \\sigma_s^2\\, ds\\right)^{1/2} &lt; \\infty\\), then \\[ X \\text{ is a $\\mathbb P$-martingale} \\iff \\mu_t = 0 \\text{ a.s.} \\] Proof: In the forward direction, given \\(X_t\\), consider a \\(\\mathbb P\\)-Brownian motion \\(W_t\\). Apply theorem 2.2 to obtain the SDE with zero drift: \\[ X_t = X_0 + \\int_0^t \\phi_s\\, dW_s \\implies dX_t = \\phi_t\\, dW_t \\] The converse is too difficult to prove here. Theorem 2.4 (exponential martingale characterization) For previsible \\(\\sigma_t\\), consider the process \\[ dX_t = \\sigma_t X_t\\, dW_t \\iff X_t = X_0 \\exp \\left( \\int_0^t \\sigma_s\\, dW_s - \\dfrac 1 2 \\int_0^t \\sigma_s^2\\, ds \\right) \\] Then \\(\\mathbb{E}\\exp \\left(\\dfrac 1 2 \\int_0^T \\sigma_s^2\\, ds\\right) &lt; \\infty \\implies X_t\\) is a \\(\\mathbb P\\)-martingale. "],["application-to-financial-strategies.html", "3 Application to financial strategies Preliminaries", " 3 Application to financial strategies Preliminaries Definition 3.1 (portfolio) A (stock-bond) portfolio is a pair \\((\\phi_t, \\psi_t)\\) of real-valued processes. The security component \\(\\phi\\) should be \\(\\mathcal F\\)-previsible. Note that left-continuous (left-limit approaches correctly) \\(\\phi_t(\\forall \\omega)\\) is previsible. "],["bibliography.html", "Bibliography", " Bibliography "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
